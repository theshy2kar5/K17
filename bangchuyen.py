"""
Ch∆∞∆°ng tr√¨nh ƒë·∫øm s·ªë l∆∞·ª£ng h√¨nh tr√≤n v∆∞·ª£t qua v√πng ·∫£o tr√™n bƒÉng chuy·ªÅn (KH√îNG V·∫º LINE)
Phi√™n b·∫£n t·ªëi ∆∞u v·ªõi Kalman Filter, HoughCircles v√† thu·∫≠t to√°n tracking n√¢ng cao
"""

import cv2 as cv
import numpy as np
from collections import deque


class KalmanTracker:
    """Kalman Filter ƒë·ªÉ tracking v√† d·ª± ƒëo√°n v·ªã tr√≠ object"""
    def __init__(self, initial_position):
        self.kf = cv.KalmanFilter(4, 2)
        self.kf.measurementMatrix = np.array([[1, 0, 0, 0],
                                               [0, 1, 0, 0]], np.float32)
        self.kf.transitionMatrix = np.array([[1, 0, 1, 0],
                                              [0, 1, 0, 1],
                                              [0, 0, 1, 0],
                                              [0, 0, 0, 1]], np.float32)
        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03
        
        self.kf.statePost = np.array([[initial_position[0]], 
                                       [initial_position[1]], 
                                       [0], [0]], np.float32)
        self.predicted = initial_position
        
    def predict(self):
        """D·ª± ƒëo√°n v·ªã tr√≠ ti·∫øp theo"""
        prediction = self.kf.predict()
        self.predicted = (int(prediction[0][0]), int(prediction[1][0]))
        return self.predicted
    
    def update(self, measurement):
        """C·∫≠p nh·∫≠t v·ªõi v·ªã tr√≠ ƒëo ƒë∆∞·ª£c th·ª±c t·∫ø"""
        self.kf.correct(np.array([[np.float32(measurement[0])],
                                   [np.float32(measurement[1])]]))
        return measurement


class TrackedObject:
    """ƒê·∫°i di·ªán cho m·ªôt object ƒëang ƒë∆∞·ª£c tracking"""
    def __init__(self, obj_id, position):
        self.id = obj_id
        self.kalman = KalmanTracker(position)
        self.positions = deque([position], maxlen=15)
        self.missed_frames = 0
        self.counted = False
        self.age = 0
        
    def predict(self):
        """D·ª± ƒëo√°n v·ªã tr√≠ ti·∫øp theo"""
        return self.kalman.predict()
    
    def update(self, position):
        """C·∫≠p nh·∫≠t v·ªõi v·ªã tr√≠ th·ª±c t·∫ø"""
        self.kalman.update(position)
        self.positions.append(position)
        self.missed_frames = 0
        self.age += 1
        
    def mark_missed(self):
        """ƒê√°nh d·∫•u frame b·ªã miss"""
        self.missed_frames += 1
        predicted = self.predict()
        self.positions.append(predicted)
        
    def get_current_position(self):
        """L·∫•y v·ªã tr√≠ hi·ªán t·∫°i"""
        return self.positions[-1]
    
    def is_lost(self, max_missed=10):
        """Ki·ªÉm tra object c√≥ b·ªã m·∫•t kh√¥ng"""
        return self.missed_frames > max_missed


def detect_circles_hybrid(frame, fg_mask):
    """
    Ph√°t hi·ªán h√¨nh tr√≤n b·∫±ng ph∆∞∆°ng ph√°p k·∫øt h·ª£p:
    1. Contour-based detection (t·ª´ background subtraction)
    2. Hough Circles (cho ƒë·ªô ch√≠nh x√°c cao)
    """
    circles = []
    
    # PH∆Ø∆†NG PH√ÅP 1: Contour-based (nhanh, ·ªïn ƒë·ªãnh)
    contours, _ = cv.findContours(fg_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        area = cv.contourArea(contour)
        
        if 800 < area < 50000:
            perimeter = cv.arcLength(contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter ** 2)
                
                if circularity > 0.35:  # Ng∆∞·ª°ng tr√≤n linh ho·∫°t h∆°n
                    M = cv.moments(contour)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])
                        
                        # T√≠nh b√°n k√≠nh ∆∞·ªõc l∆∞·ª£ng
                        radius = int(np.sqrt(area / np.pi))
                        
                        circles.append({
                            'center': (cx, cy),
                            'radius': radius,
                            'area': area,
                            'circularity': circularity,
                            'method': 'contour'
                        })
    
    # PH∆Ø∆†NG PH√ÅP 2: Hough Circles (ch√≠nh x√°c cho h√¨nh tr√≤n r√µ)
    # Ch·ªâ ch·∫°y khi c·∫ßn thi·∫øt ƒë·ªÉ ti·∫øt ki·ªám t√†i nguy√™n
    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    gray_blurred = cv.GaussianBlur(gray, (9, 9), 2)
    
    detected_circles = cv.HoughCircles(
        gray_blurred,
        cv.HOUGH_GRADIENT,
        dp=1.2,
        minDist=50,
        param1=50,
        param2=30,
        minRadius=15,
        maxRadius=80
    )
    
    if detected_circles is not None:
        detected_circles = np.uint16(np.around(detected_circles))
        for circle in detected_circles[0, :]:
            cx, cy, r = circle
            area = np.pi * r * r
            
            if 800 < area < 50000:
                circles.append({
                    'center': (int(cx), int(cy)),
                    'radius': int(r),
                    'area': area,
                    'circularity': 1.0,  # Hough circles lu√¥n tr√≤n
                    'method': 'hough'
                })
    
    # Lo·∫°i b·ªè tr√πng l·∫∑p (merge circles g·∫ßn nhau)
    circles = merge_nearby_circles(circles, distance_threshold=40)
    
    return circles


def merge_nearby_circles(circles, distance_threshold=40):
    """G·ªôp c√°c circles g·∫ßn nhau th√†nh m·ªôt"""
    if len(circles) <= 1:
        return circles
    
    merged = []
    used = set()
    
    for i, circle1 in enumerate(circles):
        if i in used:
            continue
            
        group = [circle1]
        cx1, cy1 = circle1['center']
        
        for j, circle2 in enumerate(circles[i+1:], start=i+1):
            if j in used:
                continue
                
            cx2, cy2 = circle2['center']
            distance = np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)
            
            if distance < distance_threshold:
                group.append(circle2)
                used.add(j)
        
        # L·∫•y circle t·ªët nh·∫•t trong nh√≥m (∆∞u ti√™n circularity cao)
        best_circle = max(group, key=lambda c: c['circularity'])
        merged.append(best_circle)
        used.add(i)
    
    return merged


def match_objects_to_detections(tracked_objects, detected_circles, max_distance=100):
    """
    Kh·ªõp objects ƒëang track v·ªõi detections m·ªõi b·∫±ng Hungarian Algorithm (simplified)
    """
    if not tracked_objects or not detected_circles:
        return [], detected_circles
    
    # Ma tr·∫≠n kho·∫£ng c√°ch
    distance_matrix = np.zeros((len(tracked_objects), len(detected_circles)))
    
    for i, obj in enumerate(tracked_objects):
        predicted_pos = obj.predict()
        
        for j, circle in enumerate(detected_circles):
            cx, cy = circle['center']
            dist = np.sqrt((predicted_pos[0] - cx)**2 + (predicted_pos[1] - cy)**2)
            distance_matrix[i, j] = dist
    
    # Simple greedy matching (c√≥ th·ªÉ thay b·∫±ng Hungarian n·∫øu c·∫ßn)
    matches = []
    unmatched_detections = list(range(len(detected_circles)))
    
    for obj_idx in range(len(tracked_objects)):
        if len(unmatched_detections) == 0:
            break
            
        # T√¨m detection g·∫ßn nh·∫•t v·ªõi object n√†y
        min_dist = float('inf')
        min_det_idx = -1
        
        for det_idx in unmatched_detections:
            if distance_matrix[obj_idx, det_idx] < min_dist:
                min_dist = distance_matrix[obj_idx, det_idx]
                min_det_idx = det_idx
        
        # Ch·ªâ match n·∫øu ƒë·ªß g·∫ßn
        if min_dist < max_distance:
            matches.append((obj_idx, min_det_idx))
            unmatched_detections.remove(min_det_idx)
    
    # C√°c detections ch∆∞a match
    unmatched_circles = [detected_circles[i] for i in unmatched_detections]
    
    return matches, unmatched_circles


def main():
    # ==================== KH·ªûI T·∫†O VIDEO ====================
    vid = cv.VideoCapture("bang_chuyen.mp4")
    
    if not vid.isOpened():
        print("‚ùå L·ªói: Kh√¥ng th·ªÉ m·ªü file video 'bang_chuyen.mp4'")
        return
    
    frame_width = int(vid.get(cv.CAP_PROP_FRAME_WIDTH))
    frame_height = int(vid.get(cv.CAP_PROP_FRAME_HEIGHT))
    fps = int(vid.get(cv.CAP_PROP_FPS))
    total_frames = int(vid.get(cv.CAP_PROP_FRAME_COUNT))
    
    print(f"üìπ Video: {frame_width}x{frame_height}, FPS: {fps}, T·ªïng frames: {total_frames}")
    
    # ==================== THI·∫æT L·∫¨P THAM S·ªê ====================
    # V·ªã tr√≠ line ·∫£o (KH√îNG V·∫º tr√™n video)
    line_position = int(frame_width * 0.65)
    
    # Bi·∫øn ƒë·∫øm
    count = 0
    tracked_objects = []
    next_object_id = 0
    
    # Background Subtractor v·ªõi tham s·ªë t·ªëi ∆∞u
    bg_subtractor = cv.createBackgroundSubtractorMOG2(
        history=500,
        varThreshold=25,
        detectShadows=False
    )
    
    frame_count = 0
    
    print(f"‚öôÔ∏è  Line ƒë·∫øm (M√ÄU ƒê·ªé) ·ªü v·ªã tr√≠: x = {line_position}")
    print("‚å®Ô∏è  Nh·∫•n 'q' ƒë·ªÉ tho√°t, 'p' ƒë·ªÉ pause\n")
    print(f"{'='*70}")
    
    paused = False
    
    # ==================== X·ª¨ L√ù VIDEO ====================
    while True:
        if not paused:
            ret, frame = vid.read()
            if not ret:
                break
            
            frame_count += 1
            
            # √Åp d·ª•ng background subtraction
            fg_mask = bg_subtractor.apply(frame, learningRate=0.01)
            
            # X·ª≠ l√Ω mask
            _, fg_mask = cv.threshold(fg_mask, 250, 255, cv.THRESH_BINARY)
            kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))
            fg_mask = cv.morphologyEx(fg_mask, cv.MORPH_CLOSE, kernel, iterations=2)
            fg_mask = cv.morphologyEx(fg_mask, cv.MORPH_OPEN, kernel)
            
            # Ph√°t hi·ªán circles
            detected_circles = detect_circles_hybrid(frame, fg_mask)
            
            # Match v·ªõi tracked objects
            matches, unmatched_circles = match_objects_to_detections(
                tracked_objects, detected_circles, max_distance=80
            )
            
            # C·∫≠p nh·∫≠t matched objects
            updated_objects = []
            for obj_idx, det_idx in matches:
                obj = tracked_objects[obj_idx]
                circle = detected_circles[det_idx]
                
                old_pos = obj.get_current_position()
                new_pos = circle['center']
                
                obj.update(new_pos)
                
                # Ki·ªÉm tra v∆∞·ª£t line (t·ª´ tr√°i sang ph·∫£i)
                if not obj.counted and obj.age > 3:  # Ch·ªâ ƒë·∫øm sau khi track ·ªïn ƒë·ªãnh
                    if old_pos[0] < line_position <= new_pos[0]:
                        count += 1
                        obj.counted = True
                        print(f"‚úì Frame {frame_count:4d}: Object #{obj.id:3d} v∆∞·ª£t qua line ‚Üí T·ªïng: {count}")
                
                updated_objects.append(obj)
            
            # X·ª≠ l√Ω unmatched objects (b·ªã miss)
            for i, obj in enumerate(tracked_objects):
                if not any(i == match[0] for match in matches):
                    obj.mark_missed()
                    if not obj.is_lost(max_missed=15):
                        updated_objects.append(obj)
            
            tracked_objects = updated_objects
            
            # T·∫°o objects m·ªõi t·ª´ unmatched detections
            for circle in unmatched_circles:
                cx, cy = circle['center']
                
                # Ch·ªâ t·∫°o object m·ªõi ·ªü ph√≠a b√™n tr√°i line
                if cx < line_position - 30:
                    new_obj = TrackedObject(next_object_id, (cx, cy))
                    tracked_objects.append(new_obj)
                    next_object_id += 1
            
            # ==================== HI·ªÇN TH·ªä V·ªöI LINE M√ÄU ƒê·ªé ====================
            display_frame = frame.copy()
            
            # V·∫º LINE M√ÄU ƒê·ªé ƒê·ªÇ ƒê·∫æM
            cv.line(display_frame, (line_position, 0), (line_position, frame_height), (0, 0, 255), 3)
            
            # V·∫Ω tracking info
            for obj in tracked_objects:
                pos = obj.get_current_position()
                color = (0, 255, 0) if not obj.counted else (0, 165, 255)
                cv.circle(display_frame, pos, 8, color, -1)
                cv.circle(display_frame, pos, 20, color, 2)
            
            # Hi·ªÉn th·ªã th√¥ng tin
            cv.putText(display_frame, f"Count: {count}", (20, 50), 
                       cv.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
            cv.putText(display_frame, f"Frame: {frame_count}/{total_frames}", (20, 100), 
                       cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv.putText(display_frame, f"Tracking: {len(tracked_objects)}", (20, 135), 
                       cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            # Progress bar
            progress = int((frame_count / total_frames) * 100)
            cv.rectangle(display_frame, (20, frame_height - 40), 
                        (20 + int(progress * 6), frame_height - 20), (0, 255, 0), -1)
            cv.putText(display_frame, f"{progress}%", (20 + int(progress * 6) + 10, frame_height - 23), 
                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Hi·ªÉn th·ªã frame
        cv.imshow("Object Counting - Red Line Detection", display_frame)
        
        # X·ª≠ l√Ω ph√≠m
        key = cv.waitKey(1) & 0xFF
        if key == ord("q"):
            break
        elif key == ord("p"):
            paused = not paused
            print("‚è∏Ô∏è  PAUSED" if paused else "‚ñ∂Ô∏è  RESUMED")
        
        # Log m·ªói 100 frames
        if not paused and frame_count % 100 == 0:
            print(f"üìä Frame: {frame_count}/{total_frames} | Count: {count} | Tracking: {len(tracked_objects)}")
    
    # ==================== K·∫æT TH√öC ====================
    print(f"\n{'='*70}")
    print(f"‚úÖ HO√ÄN TH√ÄNH!")
    print(f"{'='*70}")
    print(f"üéØ T·ªïng s·ªë v·∫≠t th·ªÉ ƒë√£ qua line: {count}")
    print(f"üìπ T·ªïng s·ªë frames ƒë√£ x·ª≠ l√Ω: {frame_count}")
    print(f"üé¨ T·ª∑ l·ªá ho√†n th√†nh: {(frame_count/total_frames)*100:.1f}%")
    print(f"{'='*70}")
    
    vid.release()
    cv.destroyAllWindows()


if __name__ == "__main__":
    main()