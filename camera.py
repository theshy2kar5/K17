# H·ªá th·ªëng ph√°t hi·ªán chuy·ªÉn ƒë·ªông v·ªõi Camera
import cv2
import numpy as np
import time
import datetime
import os
from collections import deque

class MotionDetector:
    def __init__(self, min_area=500, delta_threshold=25, blur_size=(21, 21)):
        """Kh·ªüi t·∫°o b·ªô ph√°t hi·ªán chuy·ªÉn ƒë·ªông"""
        self.min_area = min_area
        self.delta_threshold = delta_threshold
        self.blur_size = blur_size
        self.background = None
        self.motion_counter = 0
        self.total_motion_detected = 0
        
        # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ
        self.output_dir = "motion_detection_output"
        self.video_dir = os.path.join(self.output_dir, "videos")
        self.image_dir = os.path.join(self.output_dir, "snapshots")
        
        for directory in [self.output_dir, self.video_dir, self.image_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)
        
        # Video recording
        self.is_recording = False
        self.video_writer = None
        self.motion_frames_buffer = deque(maxlen=30)
        
    def detect_motion(self, frame, background):
        """Ph√°t hi·ªán chuy·ªÉn ƒë·ªông trong khung h√¨nh so v·ªõi n·ªÅn"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, self.blur_size, 0)

        # T√≠nh hi·ªáu gi·ªØa khung h√¨nh hi·ªán t·∫°i v√† n·ªÅn
        frame_delta = cv2.absdiff(background, gray)
        thresh = cv2.threshold(frame_delta, self.delta_threshold, 255, cv2.THRESH_BINARY)[1]

        # M·ªü r·ªông ng∆∞·ª°ng ƒë·ªÉ l·∫•p ƒë·∫ßy c√°c l·ªó
        thresh = cv2.dilate(thresh, None, iterations=2)

        # T√¨m c√°c ƒë∆∞·ªùng vi·ªÅn
        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        motion_contours = []
        for contour in contours:
            if cv2.contourArea(contour) < self.min_area:
                continue
            motion_contours.append(contour)

        return motion_contours, thresh
    
    def update_background(self, frame, alpha=0.01):
        """C·∫≠p nh·∫≠t n·ªÅn ƒë·ªông ƒë·ªÉ th√≠ch nghi v·ªõi m√¥i tr∆∞·ªùng"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, self.blur_size, 0)
        
        if self.background is None:
            self.background = gray.copy().astype("float")
        else:
            cv2.accumulateWeighted(gray, self.background, alpha)
    
    def draw_info(self, frame, contours, motion_detected, fps=0):
        """V·∫Ω th√¥ng tin l√™n khung h√¨nh"""
        height, width = frame.shape[:2]
        
        # V·∫Ω c√°c h·ªôp gi·ªõi h·∫°n v√† th√¥ng tin cho m·ªói ƒë·ªëi t∆∞·ª£ng
        for i, contour in enumerate(contours):
            (x, y, w, h) = cv2.boundingRect(contour)
            
            # V·∫Ω h·ªôp
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            
            # T√≠nh di·ªán t√≠ch
            area = cv2.contourArea(contour)
            
            # V·∫Ω nh√£n
            label = f"Obj{i+1}: {area:.0f}px"
            cv2.putText(frame, label, (x, y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # V·∫Ω tr·ªçng t√¢m
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)
        
        # T·∫°o overlay cho th√¥ng tin
        overlay = frame.copy()
        
        # V·∫Ω thanh tr·∫°ng th√°i ph√≠a tr√™n
        cv2.rectangle(overlay, (0, 0), (width, 120), (0, 0, 0), -1)
        frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)
        
        # Th√¥ng tin tr·∫°ng th√°i
        status_text = "‚ö† CHUY·ªÇN ƒê·ªòNG PH√ÅT HI·ªÜN" if motion_detected else "‚úì Kh√¥ng c√≥ chuy·ªÉn ƒë·ªông"
        status_color = (0, 0, 255) if motion_detected else (0, 255, 0)
        
        cv2.putText(frame, status_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        
        # Timestamp
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        cv2.putText(frame, f"Th·ªùi gian: {timestamp}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Th√¥ng tin chi ti·∫øt
        cv2.putText(frame, f"ƒê·ªëi t∆∞·ª£ng: {len(contours)}", (10, 85),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 105),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # T·ªïng s·ªë l·∫ßn ph√°t hi·ªán
        cv2.putText(frame, f"T·ªïng ph√°t hi·ªán: {self.total_motion_detected}", (width - 250, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Ch·∫ø ƒë·ªô ghi
        if self.is_recording:
            cv2.circle(frame, (width - 30, 60), 10, (0, 0, 255), -1)
            cv2.putText(frame, "REC", (width - 70, 65),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # H∆∞·ªõng d·∫´n ph√≠m
        info_y = height - 80
        cv2.putText(frame, "Ph√≠m t·∫Øt: [Q]Tho√°t [R]Ghi [S]Ch·ª•p [B]Reset n·ªÅn [+/-]ƒê·ªô nh·∫°y",
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return frame
    
    def start_recording(self, frame_shape, fps=20.0):
        """B·∫Øt ƒë·∫ßu ghi video"""
        if not self.is_recording:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.video_dir, f"motion_{timestamp}.avi")
            
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            self.video_writer = cv2.VideoWriter(
                filename, fourcc, fps,
                (frame_shape[1], frame_shape[0])
            )
            self.is_recording = True
            print(f"‚ñ∂ B·∫Øt ƒë·∫ßu ghi: {filename}")
            return filename
        return None
    
    def stop_recording(self):
        """D·ª´ng ghi video"""
        if self.is_recording and self.video_writer is not None:
            self.video_writer.release()
            self.video_writer = None
            self.is_recording = False
            print("‚èπ ƒê√£ d·ª´ng ghi video")
    
    def save_snapshot(self, frame):
        """L∆∞u ·∫£nh ch·ª•p m√†n h√¨nh"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(self.image_dir, f"snapshot_{timestamp}.jpg")
        cv2.imwrite(filename, frame)
        print(f"üì∏ ƒê√£ l∆∞u ·∫£nh: {filename}")
        return filename

def main():
    """H√†m ch√≠nh"""
    print("=" * 60)
    print("H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN CHUY·ªÇN ƒê·ªòNG")
    print("=" * 60)
    print("Ph√≠m t·∫Øt:")
    print("  [Q] - Tho√°t ch∆∞∆°ng tr√¨nh")
    print("  [R] - B·∫≠t/T·∫Øt ghi video")
    print("  [S] - Ch·ª•p ·∫£nh m√†n h√¨nh")
    print("  [B] - Reset n·ªÅn (c·∫≠p nh·∫≠t n·ªÅn m·ªõi)")
    print("  [+] - TƒÉng ƒë·ªô nh·∫°y (gi·∫£m ng∆∞·ª°ng)")
    print("  [-] - Gi·∫£m ƒë·ªô nh·∫°y (tƒÉng ng∆∞·ª°ng)")
    print("  [A] - TƒÉng di·ªán t√≠ch t·ªëi thi·ªÉu")
    print("  [D] - Gi·∫£m di·ªán t√≠ch t·ªëi thi·ªÉu")
    print("=" * 60)
    
    # Kh·ªüi t·∫°o camera
    print("\nüé• ƒêang kh·ªüi ƒë·ªông camera...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("‚ùå L·ªói: Kh√¥ng th·ªÉ m·ªü camera!")
        return
    
    # Thi·∫øt l·∫≠p camera
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    print("‚úì Camera ƒë√£ s·∫µn s√†ng!")
    time.sleep(2.0)
    
    # Kh·ªüi t·∫°o detector
    detector = MotionDetector(min_area=500, delta_threshold=25)
    
    # L·∫•y khung h√¨nh n·ªÅn ban ƒë·∫ßu
    print("üì∑ ƒêang ch·ª•p ·∫£nh n·ªÅn...")
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc t·ª´ camera!")
        cap.release()
        return
    
    detector.background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    detector.background = cv2.GaussianBlur(detector.background, (21, 21), 0).astype("float")
    print("‚úì ƒê√£ thi·∫øt l·∫≠p n·ªÅn!\n")
    
    # Bi·∫øn ƒë·∫øm
    frame_count = 0
    start_time = time.time()
    auto_record = False
    motion_detected_last = False
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ö† Kh√¥ng th·ªÉ ƒë·ªçc frame!")
                break
            
            frame_count += 1
            
            # Ph√°t hi·ªán chuy·ªÉn ƒë·ªông
            motion_contours, thresh = detector.detect_motion(frame, detector.background.astype("uint8"))
            motion_detected = len(motion_contours) > 0
            
            # ƒê·∫øm chuy·ªÉn ƒë·ªông
            if motion_detected and not motion_detected_last:
                detector.total_motion_detected += 1
            motion_detected_last = motion_detected
            
            # C·∫≠p nh·∫≠t n·ªÅn ƒë·ªông
            detector.update_background(frame, alpha=0.01)
            
            # T√≠nh FPS
            elapsed = time.time() - start_time
            fps = frame_count / elapsed if elapsed > 0 else 0
            
            # V·∫Ω th√¥ng tin
            display_frame = detector.draw_info(frame.copy(), motion_contours, motion_detected, fps)
            
            # Auto recording
            if auto_record:
                if motion_detected and not detector.is_recording:
                    detector.start_recording(frame.shape)
                
                if detector.is_recording:
                    detector.video_writer.write(display_frame)
            
            # Hi·ªÉn th·ªã
            cv2.imshow("Motion Detection System - Press Q to quit", display_frame)
            
            # Hi·ªÉn th·ªã threshold (debug)
            if motion_detected:
                cv2.imshow("Threshold (Debug)", cv2.resize(thresh, (320, 240)))
            
            # X·ª≠ l√Ω ph√≠m
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == ord('Q'):
                print("\nüëã ƒêang tho√°t...")
                break
                
            elif key == ord('r') or key == ord('R'):
                auto_record = not auto_record
                if auto_record:
                    print("üî¥ Ch·∫ø ƒë·ªô t·ª± ƒë·ªông ghi: B·∫¨T")
                else:
                    print("‚ö™ Ch·∫ø ƒë·ªô t·ª± ƒë·ªông ghi: T·∫ÆT")
                    detector.stop_recording()
                    
            elif key == ord('s') or key == ord('S'):
                detector.save_snapshot(display_frame)
                
            elif key == ord('b') or key == ord('B'):
                detector.background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                detector.background = cv2.GaussianBlur(detector.background, (21, 21), 0).astype("float")
                print("üîÑ ƒê√£ reset n·ªÅn!")
                
            elif key == ord('+') or key == ord('='):
                detector.delta_threshold = max(5, detector.delta_threshold - 5)
                print(f"‚¨Ü ƒê·ªô nh·∫°y tƒÉng (Ng∆∞·ª°ng: {detector.delta_threshold})")
                
            elif key == ord('-') or key == ord('_'):
                detector.delta_threshold = min(100, detector.delta_threshold + 5)
                print(f"‚¨á ƒê·ªô nh·∫°y gi·∫£m (Ng∆∞·ª°ng: {detector.delta_threshold})")
                
            elif key == ord('a') or key == ord('A'):
                detector.min_area = min(5000, detector.min_area + 100)
                print(f"üìè Di·ªán t√≠ch t·ªëi thi·ªÉu: {detector.min_area}px")
                
            elif key == ord('d') or key == ord('D'):
                detector.min_area = max(100, detector.min_area - 100)
                print(f"üìè Di·ªán t√≠ch t·ªëi thi·ªÉu: {detector.min_area}px")
    
    except KeyboardInterrupt:
        print("\n‚ö† Ng·∫Øt b·ªüi ng∆∞·ªùi d√πng...")
    
    finally:
        # D·ªçn d·∫πp
        print("\nüßπ ƒêang d·ªçn d·∫πp...")
        detector.stop_recording()
        cap.release()
        cv2.destroyAllWindows()
        
        # Th·ªëng k√™
        print("\n" + "=" * 60)
        print("TH·ªêNG K√ä")
        print("=" * 60)
        print(f"T·ªïng s·ªë frame: {frame_count}")
        print(f"FPS trung b√¨nh: {fps:.1f}")
        print(f"T·ªïng l·∫ßn ph√°t hi·ªán chuy·ªÉn ƒë·ªông: {detector.total_motion_detected}")
        print(f"Th·ªùi gian ch·∫°y: {elapsed:.1f} gi√¢y")
        print("=" * 60)
        print("‚úì Ch∆∞∆°ng tr√¨nh ƒë√£ k·∫øt th√∫c.")

if __name__ == "__main__":
    main()